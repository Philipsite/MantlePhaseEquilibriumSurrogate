
using Flux
using CSV, DataFrames
using JLD2
using Sprout
using CairoMakie


# LOAD DATA
#-----------------------------------------------------------------------
DATA_DIR = joinpath("data", "generated_dataset")
x_train = CSV.read(joinpath(DATA_DIR, "sb21_02Oct25_train_x.csv"), DataFrame);
y_train = CSV.read(joinpath(DATA_DIR, "sb21_02Oct25_train_y.csv"), DataFrame);
x_val = CSV.read(joinpath(DATA_DIR, "sb21_02Oct25_val_x.csv"), DataFrame);
y_val = CSV.read(joinpath(DATA_DIR, "sb21_02Oct25_val_y.csv"), DataFrame);
x_train, ğ‘£_train, ğ—_ss_train, Ï_train, Îš_train, Î¼_train = preprocess_data(x_train, y_train);
x_val, ğ‘£_val, ğ—_ss_val, Ï_val, Îš_val, Î¼_val = preprocess_data(x_val, y_val);

# Normalise inputs
xNorm = Norm(x_train);
x_train = xNorm(x_train);
x_val = xNorm(x_val);

# Scale outputs
ğ—Scale = MinMaxScaler(ğ—_ss_train);
ğ—_ss_train = ğ—Scale(ğ—_ss_train);
ğ—_ss_val = ğ—Scale(ğ—_ss_val);

ğ‘£Scale = MinMaxScaler(ğ‘£_train);
ğ‘£_train = ğ‘£Scale(ğ‘£_train);
ğ‘£_val = ğ‘£Scale(ğ‘£_val);

# Setup DataLoader
batch_size = 4096;
loader = Flux.DataLoader((x_train, (ğ‘£_train, ğ—_ss_train)), batchsize=batch_size, shuffle=true);


# SETUP LOSS & METRICS
#----------------------------------------------------------------------
# Normalisation/scaling structures must live on the same device as the model is trained on
# for training on GPU move normalisers/scalers/pure_phase_comp to GPU; e.g. xNorm_gpu = xNorm |> gpu
xNorm_gpu = xNorm |> gpu;
ğ‘£Scale_gpu = ğ‘£Scale |> gpu;
ğ—Scale_gpu = ğ—Scale |> gpu;
pp_mat_gpu = reshape(PP_COMP_adj, 6, :) |> gpu;

function loss((ğ‘£_Å·, ğ—_Å·), (ğ‘£, ğ—), x)
    return sum(abs2, ğ‘£_Å· .- ğ‘£) + sum(abs2, ğ—_Å· .- ğ—) + misfit.mass_balance_abs_misfit((descale(ğ‘£Scale_gpu, ğ‘£_Å·), descale(ğ—Scale_gpu, ğ—_Å·)), denorm(xNorm_gpu, x)[3:end,:,:], agg=sum, pure_phase_comp=pp_mat_gpu) + misfit.closure_condition((descale(ğ‘£Scale_gpu, ğ‘£_Å·), descale(ğ—Scale_gpu, ğ—_Å·)), (ğ‘£, ğ—), agg=sum)
end
# Metrics (for validation only, must follow signature (Å·, y) -> Real)
function mass_balance_metric((ğ‘£_Å·, ğ—_Å·), (_, _))
    return misfit.mass_balance_abs_misfit((descale(ğ‘£Scale, ğ‘£_Å·), descale(ğ—Scale, ğ—_Å·)), denorm(xNorm, x_val)[3:end,:,:], agg=mean)
end
function mae_ğ‘£(Å·, y)
    return misfit.mae_no_zeros(descale(ğ‘£Scale, Å·[1]), descale(ğ‘£Scale, y[1]))
end
function mae_ğ—(Å·, y)
    return misfit.mae_no_zeros(descale(ğ—Scale, Å·[2]), descale(ğ—Scale, y[2]))
end
function closure_metric((ğ‘£_Å·, ğ—_Å·), y)
    return misfit.closure_condition((descale(ğ‘£Scale, ğ‘£_Å·), descale(ğ—Scale, ğ—_Å·)), y, agg=mean)
end

metrics = [mass_balance_metric, mae_ğ‘£, mae_ğ—, closure_metric];


# SETUP MODEL
#----------------------------------------------------------------------
n_layers = 4;
n_neurons = 400;
fraction_backbone_layers = 1//2;

masking_f = (clas_out, reg_out) -> (mask_ğ‘£(clas_out, reg_out[1]), mask_ğ—(clas_out, reg_out[2]));
# Load CLASSIFIER
m_classifier = create_classifier_model(2, 200, 8, 20);
model_state = JLD2.load(joinpath("models", "classifier", "saved_model.jld2"), "model_state");
Flux.loadmodel!(m_classifier, model_state);

model = create_model_pretrained_classifier(fraction_backbone_layers, n_layers, n_neurons,
                                           masking_f, m_classifier;
                                           out_dim_ğ‘£ = 20, out_dim_ğ— = (6, 14), scaled_FC = true) |> gpu_device()
opt_state = Flux.setup(Flux.Adam(0.001), model)

early_stopping = Flux.early_stopping((val_loss) -> val_loss, 10, init_score=Inf32)


# TRAIN MODEL
#-----------------------------------------------------------------------
model, opt_state, logs_t, dir = train_loop(
    model,
    loader,
    opt_state,
    (x_val, (ğ‘£_val, ğ—_ss_val)),
    loss,
    1000,
    metrics = metrics,
    early_stopping_condition=early_stopping,
    gpu_device = gpu_device(),
    save_to_subdir = "surrogate"
);

# save Norm
@save joinpath(dir, "normalisers.jld2") xNorm ğ—Scale ğ‘£Scale

# POST-TRAINING PLOTS
fig = post_training_plots(logs_t, dir)
